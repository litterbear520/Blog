---
sidebar_position: 9
description: 使用 LangChain 调用嵌入模型
---

# 调用嵌入模型

## Embeddings Models 文本嵌入模型

Embeddings Models 嵌入模型的特点：将字符串作为输入，返回一个浮点数的列表（向量）。

在NLP中，Embedding的作用就是将数据进行文本向量化。

### 阿里云千问模型访问方式

```python
from langchain_community.embeddings import DashScopeEmbeddings
from dotenv import load_dotenv
import os
load_dotenv()

DASHSCOPE_API_KEY = os.getenv('LLM_API_KEY')
# 初始化嵌入模型对象，默认模型为：text-embedding-v1
embed = DashScopeEmbeddings(dashscope_api_key=DASHSCOPE_API_KEY)

# 测试
print(embed.embed_query("我喜欢你"))
print(embed.embed_documents(['我喜欢你','我稀饭你','晚上吃什么']))
```

### 本地Ollama模型访问方式

通过langchain_ollama导入OllamaEmbeddings使用，其余不变。

```python
from langchain_ollama import OllamaEmbeddings

embed = OllamaEmbeddings(model = "qwen3-embedding:0.6b")

print(embed.embed_query("我喜欢你"))
print(embed.embed_documents(["我喜欢你","我宣你","你吃饭了吗"]))
```

## 模型使用总结

目前所掌握的LangChain API如下：

| 方式 | LLMs 大语言模型 | 聊天模型 | 文本嵌入模型 |
| --- | --- | --- | --- |
| 阿里云千问 | `from langchain_community.llms.tongyi import Tongyi` | `from langchain_community.chat_models.tongyi import ChatTongyi` | `from langchain_community.embeddings import DashScopeEmbeddings` |
| Ollama 本地模型 | `from langchain_ollama import OllamaLLM` | `from langchain_ollama import ChatOllama` | `from langchain_ollama import OllamaEmbeddings` |
