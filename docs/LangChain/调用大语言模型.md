---
sidebar_position: 6
description: 使用 LangChain 调用大语言模型
---

# 调用大语言模型

## 模型

现在市面上的模型多如牛毛，各种各样的模型不断出现，LangChain 模型组件提供了与各种模型的集成，并为所有模型提供一个精简的统一接口。

LangChain 目前支持三种类型的模型：LLMs（大语言模型）、Chat Models（聊天模型）、Embeddings Models（嵌入模型）。

- LLMs：是技术范畴的统称，指基于大参数量、海量文本训练的 Transformer 架构模型，核心能力是理解和生成自然语言，主要服务于文本生成场景
- 聊天模型：是应用范畴的细分，是专为对话场景优化的LLMs，核心能力是模拟人类对话的轮次交互，主要服务于聊天场景
- 文本嵌入模型：文本嵌入模型接收文本作为输入，得到文本的向量

LangChain 支持的三类模型，它们的使用场景不同，输入和输出不同，开发者需要根据项目需要选择相应。

我们所用的阿里云通义千问系列主要来自于：`langchain_community`包。

LLMs使用场景最多，常用大模型的下载库:

- [huggingface](https://huggingface.co/models)
- [魔搭社区](https://modelscope.cn/models)

同时LangChain支持对许多模型的调用，以通义千问为例:

```python
from langchain_community.llms.tongyi import Tongyi

# 不用qwen3-max，因为qwen3-max是聊天模型，qwen-max是大语言模型
llm = Tongyi(model='qwen-max')

# 调用invoke向模型提问
res = llm.invoke("你是谁你能做什么")
print(res)
```

如果要访问本地Ollama的模型，简单更改一下代码。
通过`langchain_ollama`包导入`OllamaLLM`类即可（请确保Ollama已经启动并提前下载好要使用的模型）。

```python
from langchain_ollama import OllamaLLM

model = OllamaLLM(model="thirdeyeai/Qwen2.5-0.5B-Instruct-uncensored:F16")

res = model.invoke(input="你是谁呀能做什么？")

print(res)
```

## 总结

通过：

- from langchain_community.llm.tongyi import Tongyi 导入通义千问系列的支持
- from langchain_ollama import OllamaLLM 导入 Ollama 系列的支持

创建好模型对象后，通过invoke对模型发起提问并可以直接打印输出结果
