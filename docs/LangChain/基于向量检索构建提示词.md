---
sidebar_position: 26
description: 基于向量检索构建提示词
---

# 基于向量检索构建提示词

## 代码实践

```python
"""
提示词: 用户的提问 + 向量库中检索到的参考资料
"""
import os

from langchain_community.chat_models import ChatTongyi
from langchain_core.vectorstores import InMemoryVectorStore
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

load_dotenv()
llm_api_key = os.getenv("LLM_API_KEY")

model = ChatTongyi(model="qwen3-max",api_key=llm_api_key)
prompt = ChatPromptTemplate.from_messages(
    [
        ("system", "以我提供的已知参考资料为主, 简洁和专业的回答用户问题。参考资料:{context}。"),
        ("user", "用户提问: {input}")
    ]
)

vector_store = InMemoryVectorStore(
    embedding=DashScopeEmbeddings(
        model="text-embedding-v4",
        dashscope_api_key=llm_api_key,
        )
    )

# 准备一下资料（向量库的数据）
# add_texts 传入一个 list[str]
vector_store.add_texts(["减肥就是要少吃多练", "在减脂期间吃东西很重要,清淡少油控制卡路里摄入并运动起来", "跑步是很好的运动哦"])

input_text = "怎么减肥？"

# 检索向量库
result = vector_store.similarity_search(input_text, k=2)
print(result)

reference_text = "["
for doc in result:
    reference_text += doc.page_content
reference_text += "]"

def print_prompt(prompt):
    print(prompt.to_string())
    print('='*20)
    return prompt

# chain
chain = prompt | print_prompt | model | StrOutputParser()

res = chain.invoke({"input": input_text,"context": reference_text})
print(res)
```

运行结果：

```text
[Document(id='2a4f0436-ed25-4dcb-a88a-6bd34587a6d6', metadata={}, page_content='减肥就是要少吃多练'), Document(id='9261962b-c47f-4bce-b3d4-0611bf77296b', metadata={}, page_content='在减脂期间吃东西很重要,清淡少油控制卡路里摄入并运动起来')]
System: 以我提供的已知参考资料为主, 简洁和专业的回答用户问题。参考资料:[减肥就是要少吃多练在减脂期间吃东西很重要,清淡少油控制卡路里摄入并运动起来]。
Human: 用户提问: 怎么减肥？
====================
减肥的关键是"少吃多练"：
- **饮食方面**：选择清淡、少油的食物，严格控制每日卡路里摄入；
- **运动方面**：坚持规律运动，增加热量消耗。

两者结合，才能有效减脂。
```

## 总结

向量存储的实例，通过`add_texts(list[str])`方法可以快速添加到向量存储中。

流程：

1. 先通过向量存储检索匹配信息
2. 将用户提问和匹配信息一同封装到提示词模板中提问模型
