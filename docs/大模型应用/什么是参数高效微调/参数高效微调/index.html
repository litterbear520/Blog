<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-大模型应用/什么是参数高效微调/参数高效微调" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">参数高效微调 | 小熊的博客</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://litterbear520.github.io/Blog/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://litterbear520.github.io/Blog/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://litterbear520.github.io/Blog/docs/大模型应用/什么是参数高效微调/参数高效微调"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="参数高效微调 | 小熊的博客"><meta data-rh="true" name="description" content="1. 定义与背景"><meta data-rh="true" property="og:description" content="1. 定义与背景"><link data-rh="true" rel="icon" href="/Blog/img/icon2.png"><link data-rh="true" rel="canonical" href="https://litterbear520.github.io/Blog/docs/大模型应用/什么是参数高效微调/参数高效微调"><link data-rh="true" rel="alternate" href="https://litterbear520.github.io/Blog/docs/大模型应用/什么是参数高效微调/参数高效微调" hreflang="en"><link data-rh="true" rel="alternate" href="https://litterbear520.github.io/Blog/docs/大模型应用/什么是参数高效微调/参数高效微调" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"大模型应用","item":"https://litterbear520.github.io/Blog/docs/大模型应用/"},{"@type":"ListItem","position":2,"name":"参数高效微调","item":"https://litterbear520.github.io/Blog/docs/大模型应用/什么是参数高效微调/参数高效微调"}]}</script><link rel="alternate" type="application/rss+xml" href="/Blog/blog/rss.xml" title="小熊的博客 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Blog/blog/atom.xml" title="小熊的博客 Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous"><link rel="stylesheet" href="/Blog/assets/css/styles.c9000783.css">
<script src="/Blog/assets/js/runtime~main.e206954c.js" defer="defer"></script>
<script src="/Blog/assets/js/main.2a81c610.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Blog/img/icon.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Blog/"><div class="navbar__logo"><img src="/Blog/img/icon.png" alt="Blog Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Blog/img/icon.png" alt="Blog Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/Blog/docs/Agent">笔记</a><a class="navbar__item navbar__link" href="/Blog/bloglist">博文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/LangChain/"><span title="LangChain" class="categoryLinkLabel_W154">LangChain</span></a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/Blog/docs/AIGC/Nano-Banana"><span title="AIGC" class="categoryLinkLabel_W154">AIGC</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/Agent/"><span title="Agent" class="categoryLinkLabel_W154">Agent</span></a><button aria-label="Expand sidebar category &#x27;Agent&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/Prompt/"><span title="Prompt" class="categoryLinkLabel_W154">Prompt</span></a><button aria-label="Expand sidebar category &#x27;Prompt&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/python/"><span title="python" class="categoryLinkLabel_W154">python</span></a><button aria-label="Expand sidebar category &#x27;python&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/云开发/"><span title="云开发" class="categoryLinkLabel_W154">云开发</span></a><button aria-label="Expand sidebar category &#x27;云开发&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/Blog/docs/大模型应用/"><span title="大模型应用" class="categoryLinkLabel_W154">大模型应用</span></a><button aria-label="Collapse sidebar category &#x27;大模型应用&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/Blog/docs/大模型应用/什么是参数高效微调/参数高效微调"><span title="什么是参数高效微调" class="categoryLinkLabel_W154">什么是参数高效微调</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Blog/docs/大模型应用/什么是参数高效微调/参数高效微调"><span title="参数高效微调" class="linkLabel_WmDU">参数高效微调</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/Blog/docs/大模型应用/大模型的微调与量化/大模型的微调与应用"><span title="大模型的微调与量化" class="categoryLinkLabel_W154">大模型的微调与量化</span></a></div></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Blog/docs/常用命令/"><span title="常用命令" class="linkLabel_WmDU">常用命令</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/深度学习/"><span title="深度学习" class="categoryLinkLabel_W154">深度学习</span></a><button aria-label="Expand sidebar category &#x27;深度学习&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/项目/"><span title="项目" class="categoryLinkLabel_W154">项目</span></a><button aria-label="Expand sidebar category &#x27;项目&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Blog/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/Blog/docs/大模型应用/"><span>大模型应用</span></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">什么是参数高效微调</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">参数高效微调</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>参数高效微调</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-定义与背景">1. 定义与背景<a href="#1-定义与背景" class="hash-link" aria-label="Direct link to 1. 定义与背景" title="Direct link to 1. 定义与背景" translate="no">​</a></h2>
<p>参数高效微调 (Parameter-Efficient Fine-Tuning, PEFT) 是一种针对大规模预训练模型（如 GPT、Qwen、DeepSeek等）的优化策略。其核心思想是通过仅调整少量参数或引入额外的轻量级模块，来实现对新任务的快速适配，而无需对整个模型进行重新训练。这种方法在资源受限的场景中表现出色，显著降低了计算成本和存储需求，同时避免了传统微调方法可能导致的过拟合问题。</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="背景">背景<a href="#背景" class="hash-link" aria-label="Direct link to 背景" title="Direct link to 背景" translate="no">​</a></h3>
<p>随着深度学习模型规模的不断增大，例如resnet18才11.7M参数，但是现在大模型几乎很少有几千万参数的存在。所以传统的全参数微调（Full Fine-Tuning）方法面临以下挑战：</p>
<ul>
<li class=""><strong>高计算成本</strong>：需要更新数十亿甚至上百亿、上千亿个参数，消耗大量GPU/TPU/NPU资源</li>
<li class=""><strong>高存储需求</strong>：每个任务都需要保存一份完整的模型副本，占用大量存储空间</li>
<li class=""><strong>易过拟合</strong>：在小数据集上微调时，容易导致模型性能下降</li>
</ul>
<p>PEFT 的出现为这些问题提供了一种高效的解决方案，使大模型能够更广泛地应用于实际场景。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-为什么要参数高效微调">2. 为什么要参数高效微调？<a href="#2-为什么要参数高效微调" class="hash-link" aria-label="Direct link to 2. 为什么要参数高效微调？" title="Direct link to 2. 为什么要参数高效微调？" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="21-传统微调的局限性">2.1 传统微调的局限性<a href="#21-传统微调的局限性" class="hash-link" aria-label="Direct link to 2.1 传统微调的局限性" title="Direct link to 2.1 传统微调的局限性" translate="no">​</a></h3>
<ul>
<li class=""><strong>资源消耗大</strong>：传统微调需要更新模型的所有参数，计算和存储开销巨大</li>
<li class=""><strong>任务间干扰</strong>：当模型需要适配多个任务时，全参数微调可能导致不同任务之间的冲突</li>
<li class=""><strong>难以扩展</strong>：对于大规模模型，全参数微调的可扩展性较差，尤其在多任务场景下</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="22-peft-的优势">2.2 PEFT 的优势<a href="#22-peft-的优势" class="hash-link" aria-label="Direct link to 2.2 PEFT 的优势" title="Direct link to 2.2 PEFT 的优势" translate="no">​</a></h3>
<ul>
<li class=""><strong>低资源需求</strong>：仅需更新少量参数或引入轻量级模块，显著降低计算和存储成本</li>
<li class=""><strong>任务隔离性</strong>：通过冻结原始模型参数，避免任务间的干扰，提升模型的鲁棒性</li>
<li class=""><strong>快速部署</strong>：适用于资源受限环境（如边缘设备），支持快速迭代和部署</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-参数高效微调的常用方法">3. 参数高效微调的常用方法<a href="#3-参数高效微调的常用方法" class="hash-link" aria-label="Direct link to 3. 参数高效微调的常用方法" title="Direct link to 3. 参数高效微调的常用方法" translate="no">​</a></h2>
<p>以下是几种主流的 PEFT 方法及其特点：</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="31-bitfit">3.1 BitFit<a href="#31-bitfit" class="hash-link" aria-label="Direct link to 3.1 BitFit" title="Direct link to 3.1 BitFit" translate="no">​</a></h3>
<p>来自论文 <a href="https://arxiv.org/abs/2106.10199" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/abs/2106.10199</a></p>
<p>BitFit 是一种稀疏微调方法，其核心思想是仅更新模型中的偏置（bias）参数，而保持权重（weight）参数不变</p>
<ul>
<li class=""><strong>优点</strong>：参数更新量极小，适合资源极度受限的场景</li>
<li class=""><strong>缺点</strong>：可能无法充分捕捉复杂任务的特征</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="32-提示微调-prompt-tuning">3.2 提示微调 (Prompt Tuning)<a href="#32-提示微调-prompt-tuning" class="hash-link" aria-label="Direct link to 3.2 提示微调 (Prompt Tuning)" title="Direct link to 3.2 提示微调 (Prompt Tuning)" translate="no">​</a></h3>
<p>Prompt Tuning 是通过优化输入的“提示”（Prompt）来调整模型行为的方法。它使用一组可训练的嵌入向量作为“软提示”，并通过优化这些嵌入向量来引导模型完成特定任务</p>
<p>软提示：在输入序列的开头或特定位置插入一组随机初始化的嵌入向量，这些向量被称为“软提示”</p>
<p>硬提示：人输入的prompt</p>
<ul>
<li class=""><strong>特点</strong>:<!-- -->
<ul>
<li class="">提示向量以嵌入形式存在，而非自然语言文本</li>
<li class="">仅需优化少量提示参数，原始模型参数保持冻结</li>
</ul>
</li>
<li class=""><strong>应用场景</strong>：分类、生成等任务。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="软提示的实现步骤">软提示的实现步骤<a href="#软提示的实现步骤" class="hash-link" aria-label="Direct link to 软提示的实现步骤" title="Direct link to 软提示的实现步骤" translate="no">​</a></h4>
<p><strong>(1)初始化软提示</strong></p>
<ul>
<li class=""><strong>嵌入向量的形状</strong>: 假设我们希望插入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> 个软提示向量，每个向量的维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span>（与模型的词嵌入维度一致）。那么软提示的形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[n, d]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">]</span></span></span></span></li>
<li class=""><strong>随机初始化</strong>: 这些嵌入向量通常使用标准正态分布或其他初始化方法（如均匀分布）进行随机初始化</li>
</ul>
<p>例如，在 PyTorch 中可以这样实现：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token keyword" style="color:#1890ff">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#1890ff">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 假设词嵌入维度为 768，软提示长度为 10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">soft_prompt_length </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">embedding_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">768</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 随机初始化软提示</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">soft_prompt </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Parameter</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">soft_prompt_length</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> embedding_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">)</span><br></span></code></pre></div></div>
<p><strong>(2)将软提示插入输入序列</strong></p>
<ul>
<li class=""><strong>原始输入</strong>：预训练模型的输入通常是经过分词器（Tokenizer）处理后的标记序列（Token Sequence），其形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>B</mi><mo separator="true">,</mo><mi>L</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[B, L, d]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">L</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">]</span></span></span></span>，其中：<!-- -->
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 是批大小 (Batch Size)</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span> 是序列长度 (Sequence Length)</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span> 是词嵌入维度 (Embedding Dimension)</li>
</ul>
</li>
<li class=""><strong>插入位置</strong>：软提示通常被插入到输入序列的开头（或特定位置），例如，将其拼接给原始输入序列的前面</li>
</ul>
<p>以下是一个简单的代码示例：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token comment" style="color:#6a737d;font-style:italic"># 假设输入序列的形状为 [B, L, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">input_embeddings </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">  </span><span class="token comment" style="color:#6a737d;font-style:italic"># 模型的原始输入，形状为 [B, L, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 扩展软提示以匹配批量大小</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">batch_size </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> input_embeddings</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">size</span><span class="token punctuation" style="color:#24292e">(</span><span class="token number" style="color:#b5641a">0</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">expanded_soft_prompt </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> soft_prompt</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">unsqueeze</span><span class="token punctuation" style="color:#24292e">(</span><span class="token number" style="color:#b5641a">0</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">expand</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">batch_size</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token operator" style="color:#24292e">-</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token operator" style="color:#24292e">-</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 形状为 [B, n, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 拼接软提示和原始输入</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">final_input_embeddings </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">cat</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">[</span><span class="token plain">expanded_soft_prompt</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> input_embeddings</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> dim</span><span class="token operator" style="color:#24292e">=</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 形状为 [B, n+L, d]</span><br></span></code></pre></div></div>
<p><strong>(3)输入到模型</strong></p>
<p>将拼接后的嵌入向量作为模型的输入，传递给预训练模型进行前向传播</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="33-前缀微调-prefix-tuning">3.3 前缀微调 (Prefix Tuning)<a href="#33-前缀微调-prefix-tuning" class="hash-link" aria-label="Direct link to 3.3 前缀微调 (Prefix Tuning)" title="Direct link to 3.3 前缀微调 (Prefix Tuning)" translate="no">​</a></h3>
<p>论文：<a href="https://arxiv.org/pdf/2101.00190.pdf" target="_blank" rel="noopener noreferrer" class="">https://arxiv.org/pdf/2101.00190.pdf</a></p>
<p>Prefix Tuning核心思想是在模型的输入中添加一组可训练的前缀向量 (Prefix Vectors)，这些向量作为任务特定的上下文信息，帮助模型适应新任务。与Prompt Tuning不同的是，Prefix Tuning的前缀向量是通常被插入到Transformer模型的每一层，而不仅仅是输入层。</p>
<ul>
<li class=""><strong>特点</strong>:<!-- -->
<ul>
<li class="">前缀向量可以看作是模型输入的一部分，影响模型的输出</li>
<li class="">相较于Prompt Tuning更灵活，适用于生成式任务（如对话、翻译）</li>
</ul>
</li>
<li class=""><strong>优势</strong>：在生成任务中表现优异，同时保留了原始模型的通用性</li>
</ul>
<p><img decoding="async" loading="lazy" alt="1754380202294" src="/Blog/assets/images/1754380202294-e876d996c4ddffdc02e12c3a2e64750b.png" width="1080" height="688" class="img_ev3q"></p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>为什么加载kv而不是q？</div><div class="admonitionContent_BuS1"><p>Query(q):表示当前需要关注的内容，通常由<mark>输入序列</mark>的每个token生成<br>
<!-- -->Key(k)和Value(v):表示上下文信息或记忆的内容，用于与query进行匹配和提取相关信息<br>
<!-- -->如果将前缀向量添加到query中，会改变模型对输入序列的关注方式，可能会导致模型偏离原始输入的语义</p></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="前缀微调的实现步骤">前缀微调的实现步骤<a href="#前缀微调的实现步骤" class="hash-link" aria-label="Direct link to 前缀微调的实现步骤" title="Direct link to 前缀微调的实现步骤" translate="no">​</a></h4>
<p><strong>(1)初始化前缀向量</strong></p>
<ul>
<li class=""><strong>前缀向量的形状</strong>：假设我们希望为每个Transformer层插入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> 个前缀向量，每个向量的维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span>（与模型的隐藏层维度一致），那么前缀向量的形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>L</mi><mo separator="true">,</mo><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[L, n, d]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">L</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">]</span></span></span></span>，其中：<!-- -->
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span> 是Transformer层数</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> 是每层前缀向量的数量</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span> 是隐藏层维度</li>
</ul>
</li>
<li class=""><strong>随机初始化</strong>：这些前缀向量通常使用标准正态分布或其他初始化方法进行随机初始化</li>
</ul>
<p>示例代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token keyword" style="color:#1890ff">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#1890ff">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 假设 Transformer 层数为 12，每层前缀向量数量为 10，隐藏层维度为 768</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">num_layers </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">12</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">prefix_length </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">hidden_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">768</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 随机初始化前缀向量</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">prefix_vectors </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Parameter</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">num_layers</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> prefix_length</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> hidden_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">)</span><br></span></code></pre></div></div>
<p><strong>(2)将前缀向量插入Transformer层</strong></p>
<ul>
<li class=""><strong>Transformer的结构</strong>：Transformer模型的每一层包含两个主要部分：<!-- -->
<ul>
<li class=""><strong>自注意力机制 (Self-Attention)</strong>：计算输入序列的注意力权重</li>
<li class=""><strong>前馈网络 (Feed-Forward Network, FFN)</strong>：对注意力输出进行非线性变换</li>
<li class=""><strong>插入位置</strong>：前缀向量被插入到每一层的自注意力机制中，作为额外的上下文信息</li>
</ul>
</li>
</ul>
<p>具体来说，前缀向量通过以下方式影响 Transformer 层：</p>
<p>1.<strong>扩展键值对 (Key-Value Pairs)</strong>：将前缀向量作为额外的键（Key）和值（Value），与原始输入序列的键值对拼接<br>
<!-- -->2.<strong>更新注意力计算</strong>：在自注意力机制中，前缀向量会参与注意力权重的计算，从而影响模型的输出</p>
<p>示例代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token comment" style="color:#6a737d;font-style:italic"># 假设输入序列的形状为 [B, L, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">input_embeddings </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 模型的原始输入，形状为 [B, L, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 扩展前缀向量以匹配批量大小</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">batch_size </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> input_embeddings</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">size</span><span class="token punctuation" style="color:#24292e">(</span><span class="token number" style="color:#b5641a">0</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">expanded_prefix_vectors </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> prefix_vectors</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">unsqueeze</span><span class="token punctuation" style="color:#24292e">(</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">expand</span><span class="token punctuation" style="color:#24292e">(</span><span class="token operator" style="color:#24292e">-</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> batch_size</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token operator" style="color:#24292e">-</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token operator" style="color:#24292e">-</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 形状为 [L, B, n, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 在每一层的自注意力机制中插入前缀向量</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> layer_idx</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> layer </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> </span><span class="token builtin" style="color:#0969da">enumerate</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">transformer_layers</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token comment" style="color:#6a737d;font-style:italic"># 获取当前层的键值对</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    key</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> value </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> layer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">compute_key_value</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">input_embeddings</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token comment" style="color:#6a737d;font-style:italic"># 拼接前缀向量</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    prefix_key</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> prefix_value </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> expanded_prefix_vectors</span><span class="token punctuation" style="color:#24292e">[</span><span class="token plain">layer_idx</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">chunk</span><span class="token punctuation" style="color:#24292e">(</span><span class="token number" style="color:#b5641a">2</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> dim</span><span class="token operator" style="color:#24292e">=</span><span class="token operator" style="color:#24292e">-</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 将前缀向量拆分为 key 和 value</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    extended_key </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">cat</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">[</span><span class="token plain">prefix_key</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> key</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> dim</span><span class="token operator" style="color:#24292e">=</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 形状为 [B, n+L, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    extended_value </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">cat</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">[</span><span class="token plain">prefix_value</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> value</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> dim</span><span class="token operator" style="color:#24292e">=</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 形状为 [B, n+L, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token comment" style="color:#6a737d;font-style:italic"># 更新注意力计算</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    attention_output </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> layer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">self_attention</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">extended_key</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> extended_value</span><span class="token punctuation" style="color:#24292e">)</span><br></span></code></pre></div></div>
<p><strong>(3) 输入到模型</strong></p>
<p>将修改后的键值对传递给 Transformer 模型的每一层，完成前向传播</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="34-p-tuning">3.4 P-Tuning<a href="#34-p-tuning" class="hash-link" aria-label="Direct link to 3.4 P-Tuning" title="Direct link to 3.4 P-Tuning" translate="no">​</a></h3>
<p>P-Tuning 是一种基于“软提示”的微调方法，其核心思想是通过引入一组可学习的“软提示”（Soft Prompt）嵌入向量来调整预训练语言模型的行为。与传统的硬提示（Hard Prompt，即直接在输入文本中添加自然语言提示）不同，P-Tuning 的软提示是以连续的嵌入向量形式存在，并且这些嵌入向量是通过训练优化得到的。</p>
<ul>
<li class=""><strong>与 Prompt Tuning 的区别</strong>：Prompt Tuning 直接使用随机初始化的嵌入向量作为软提示，而 P-Tuning 使用一个小的神经网络（称为“提示生成器”）动态生成软提示，从而增强软提示的表现力。</li>
<li class=""><strong>复杂性</strong>：Prompt Tuning 的实现较为简单，仅限于输入层；而 P-Tuning 的实现更加复杂，可能涉及多层优化或动态调整机制。</li>
<li class=""><strong>适用场景</strong>：Prompt Tuning 更适合简单任务（如分类），而 P-Tuning 更适合复杂任务（如生成式任务）。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="p-tuning-实现步骤">P-Tuning 实现步骤<a href="#p-tuning-实现步骤" class="hash-link" aria-label="Direct link to P-Tuning 实现步骤" title="Direct link to P-Tuning 实现步骤" translate="no">​</a></h4>
<p><strong>(1) 初始化软提示</strong></p>
<ul>
<li class=""><strong>软提示的形状</strong>：假设我们希望插入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span> 个软提示向量，每个向量的维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span>（与模型的词嵌入维度一致），那么软提示的形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>n</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[n, d]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">n</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">]</span></span></span></span>。</li>
<li class=""><strong>随机初始化</strong>：这些嵌入向量通常使用标准正态分布或其他初始化方法（如均匀分布）进行随机初始化。</li>
<li class=""><strong>提示生成器</strong>：P-Tuning 的软提示通常由一个小型神经网络（提示生成器）动态生成，而不是直接随机初始化。</li>
</ul>
<p>示例代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token keyword" style="color:#1890ff">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#1890ff">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 假设词嵌入维度为 768，软提示长度为 10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">soft_prompt_length </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">10</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">embedding_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">768</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 提示生成器：一个小型的神经网络用于生成软提示</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">class</span><span class="token plain"> </span><span class="token class-name" style="color:#0969da">PromptGenerator</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">def</span><span class="token plain"> </span><span class="token function" style="color:#d46b08">__init__</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> task_embedding_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> hidden_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> soft_prompt_length</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> embedding_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token builtin" style="color:#0969da">super</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">PromptGenerator</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">fc1 </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">task_embedding_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> hidden_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">relu </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">ReLU</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">fc2 </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">hidden_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> soft_prompt_length </span><span class="token operator" style="color:#24292e">*</span><span class="token plain"> embedding_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">def</span><span class="token plain"> </span><span class="token function" style="color:#d46b08">forward</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> task_embedding</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        x </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">fc1</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">task_embedding</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        x </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">relu</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        x </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">fc2</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token keyword" style="color:#1890ff">return</span><span class="token plain"> x</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">view</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">soft_prompt_length</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> embedding_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 初始化提示生成器</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">task_embedding_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">128</span><span class="token plain">  </span><span class="token comment" style="color:#6a737d;font-style:italic"># 任务相关的嵌入维度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">hidden_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">256</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">prompt_generator </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> PromptGenerator</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">task_embedding_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> hidden_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> soft_prompt_length</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> embedding_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 输入任务相关的嵌入（例如任务 ID 或任务特征）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">task_embedding </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">task_embedding_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">soft_prompt </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> prompt_generator</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">task_embedding</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 动态生成软提示</span><br></span></code></pre></div></div>
<p><strong>(2) 将软提示插入输入序列</strong></p>
<ul>
<li class=""><strong>原始输入</strong>：预训练模型的输入通常是经过分词器（Tokenizer）处理后的标记序列（Token Sequence），其形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>B</mi><mo separator="true">,</mo><mi>L</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[B, L, d]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">L</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">]</span></span></span></span>，其中：<!-- -->
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 是批大小 (Batch Size)。</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span> 是序列长度 (Sequence Length)。</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span> 是词嵌入维度 (Embedding Dimension)。</li>
</ul>
</li>
<li class=""><strong>插入位置</strong>：软提示通常被插入到输入序列的开头（或特定位置），例如，将其拼接给原始输入序列的前面。</li>
</ul>
<p>以下是一个简单的代码示例：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token comment" style="color:#6a737d;font-style:italic"># 假设输入序列的形状为 [B, L, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">input_embeddings </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">  </span><span class="token comment" style="color:#6a737d;font-style:italic"># 模型的原始输入，形状为 [B, L, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 扩展软提示以匹配批量大小</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">batch_size </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> input_embeddings</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">size</span><span class="token punctuation" style="color:#24292e">(</span><span class="token number" style="color:#b5641a">0</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">expanded_soft_prompt </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> soft_prompt</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">unsqueeze</span><span class="token punctuation" style="color:#24292e">(</span><span class="token number" style="color:#b5641a">0</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">expand</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">batch_size</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token operator" style="color:#24292e">-</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token operator" style="color:#24292e">-</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 形状为 [B, n, d]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 拼接软提示和原始输入</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">final_input_embeddings </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">cat</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">[</span><span class="token plain">expanded_soft_prompt</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> input_embeddings</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> dim</span><span class="token operator" style="color:#24292e">=</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 形状为 [B, n+L, d]</span><br></span></code></pre></div></div>
<p><strong>(3) 输入到模型</strong></p>
<p>将拼接后的嵌入向量作为模型的输入，传递给预训练模型（如 BERT、GPT 等）进行前向传播。</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="总结">总结<a href="#总结" class="hash-link" aria-label="Direct link to 总结" title="Direct link to 总结" translate="no">​</a></h2>
<ul>
<li class=""><strong>Prompt Tuning</strong> 是一种简单高效的微调方法，适合资源受限场景和简单任务。它的实现方式直接且易于理解，但表现力相对有限。</li>
<li class=""><strong>P-Tuning</strong> 则通过引入提示生成器等机制增强了软提示的表现力，适合复杂任务（如生成式任务）和对性能要求较高的场景。虽然其实现复杂度和计算成本略高，但在生成式任务中表现出色。</li>
</ul>
<p>根据具体任务需求和资源限制，可以选择合适的微调方法：</p>
<ul>
<li class="">如果任务简单且资源有限，推荐使用 Prompt Tuning。</li>
<li class="">如果任务复杂且需要更高的模型表现力，推荐使用 P-Tuning。</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="35-适配器-adapter">3.5 适配器 (Adapter)<a href="#35-适配器-adapter" class="hash-link" aria-label="Direct link to 3.5 适配器 (Adapter)" title="Direct link to 3.5 适配器 (Adapter)" translate="no">​</a></h3>
<p>适配器 (Adapter) 是一种参数高效微调 (PEFT) 方法，其核心思想是在预训练模型的某些层之间插入小型的“适配器模块” (Adapter Module)。这些模块包含少量可训练参数，用于捕获任务特定的信息，而原始模型的参数保持冻结。适配器方法通过模块化设计实现了高效的多任务学习和任务扩展。</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1核心思想">1.核心思想<a href="#1核心思想" class="hash-link" aria-label="Direct link to 1.核心思想" title="Direct link to 1.核心思想" translate="no">​</a></h4>
<p>适配器的核心思想是将任务特定的调整限制在小型模块中，而不是对整个模型进行微调。这种方法具有以下优势：</p>
<ul>
<li class=""><strong>低资源需求</strong>：仅需训练少量参数，显著降低计算和存储成本。</li>
<li class=""><strong>任务隔离性</strong>：不同任务可以使用独立的适配器模块，避免任务间的干扰。</li>
<li class=""><strong>模块化设计</strong>：适配器模块可以轻松插入到现有模型中，支持任务扩展和复用。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2适配器的结构">2.适配器的结构<a href="#2适配器的结构" class="hash-link" aria-label="Direct link to 2.适配器的结构" title="Direct link to 2.适配器的结构" translate="no">​</a></h4>
<p>适配器模块通常是一个轻量级的神经网络，其结构简单且参数量少。典型的适配器模块包括以下组件：</p>
<p>(1)<strong>降维层 (Down Projection Layer)</strong></p>
<ul>
<li class="">将输入特征映射到一个低维空间，减少计算复杂度</li>
<li class="">例如，假设输入维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span>，降维后的维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo stretchy="false">(</mo><mi>r</mi><mo>≪</mo><mi>d</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r (r \ll d)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≪</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">d</span><span class="mclose">)</span></span></span></span>，则该层的参数量为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>×</mo><mi>r</mi></mrow><annotation encoding="application/x-tex">d \times r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span></li>
</ul>
<p>(2)<strong>非线性激活函数</strong></p>
<ul>
<li class="">在降维后的特征上应用非线性激活函数（如 ReLU），增强表达能力</li>
</ul>
<p>(3)<strong>升维层 (Up Projection Layer)</strong></p>
<ul>
<li class="">将低维特征映射回原始维度，恢复特征表示</li>
<li class="">参数量为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>×</mo><mi>d</mi></mrow><annotation encoding="application/x-tex">r \times d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span></li>
</ul>
<p>(4)<strong>残差连接 (Residual Connection)</strong>：</p>
<ul>
<li class="">将适配器模块的输出与原始输入相加，确保信息流动并保留原始特征。</li>
</ul>
<p>适配器模块的典型结构如下：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>=</mo><mi>I</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo>+</mo><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub><mo stretchy="false">(</mo><mi>R</mi><mi>e</mi><mi>L</mi><mi>U</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub><mo stretchy="false">(</mo><mi>I</mi><mi>n</mi><mi>p</mi><mi>u</mi><mi>t</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Output = Input + W_{up}(ReLU(W_{down}(Input)))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal">tp</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.10903em">LU</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">n</span><span class="mord mathnormal">p</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mclose">)))</span></span></span></span></span>
<p>其中：</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{down}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>: 降维层的权重矩阵，形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>d</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[d, r]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">d</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mclose">]</span></span></span></span>。</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mrow><mi>u</mi><mi>p</mi></mrow></msub></mrow><annotation encoding="application/x-tex">W_{up}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>: 升维层的权重矩阵，形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>r</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[r, d]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">d</span><span class="mclose">]</span></span></span></span>。</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span>: 瓶颈维度 (Bottleneck Dimension)，通常远小于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span>。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="3实现步骤">3.实现步骤<a href="#3实现步骤" class="hash-link" aria-label="Direct link to 3.实现步骤" title="Direct link to 3.实现步骤" translate="no">​</a></h4>
<p><strong>(1)插入适配器模块</strong></p>
<p>适配器模块被插入到预训练模型的每一层（或部分层）中，通常位于 Transformer 层的前馈网络（Feed-Forward Network, FFN）之后。插入位置的选择取决于具体任务需求。</p>
<p>示例代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token keyword" style="color:#1890ff">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">import</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">nn </span><span class="token keyword" style="color:#1890ff">as</span><span class="token plain"> nn</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">class</span><span class="token plain"> </span><span class="token class-name" style="color:#0969da">Adapter</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">def</span><span class="token plain"> </span><span class="token function" style="color:#d46b08">__init__</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> input_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> bottleneck_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token builtin" style="color:#0969da">super</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">Adapter</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">down_proj </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">input_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> bottleneck_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">up_proj </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Linear</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">bottleneck_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> input_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">activation </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">ReLU</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">def</span><span class="token plain"> </span><span class="token function" style="color:#d46b08">forward</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> x</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        residual </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> x</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        x </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">down_proj</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        x </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">activation</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        x </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">up_proj</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token keyword" style="color:#1890ff">return</span><span class="token plain"> x </span><span class="token operator" style="color:#24292e">+</span><span class="token plain"> residual </span><span class="token comment" style="color:#6a737d;font-style:italic"># 残差连接</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 假设 Transformer 层的隐藏层维度为 768，瓶颈维度为 64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">input_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">768</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">bottleneck_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">64</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 初始化适配器模块</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">adapter </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> Adapter</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">input_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> bottleneck_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 修改Transformer层的前向传播以包含适配器</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">class</span><span class="token plain"> </span><span class="token class-name" style="color:#0969da">LLMLayer</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">BertLayer</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">def</span><span class="token plain"> </span><span class="token function" style="color:#d46b08">__init__</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> config</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token builtin" style="color:#0969da">super</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">config</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        input_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">768</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 假设隐藏层维度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        bottleneck_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token number" style="color:#b5641a">64</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 假设瓶颈维度</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">adapter </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> Adapter</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">input_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> bottleneck_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 添加适配器</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">def</span><span class="token plain"> </span><span class="token function" style="color:#d46b08">forward</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> hidden_states</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 简化参数，实际需匹配原方法</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token comment" style="color:#6a737d;font-style:italic"># 原Transformer层的计算（如自注意力、FFN）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        hidden_states </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token builtin" style="color:#0969da">super</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">forward</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">hidden_states</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">.</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#24292e">[</span><span class="token number" style="color:#b5641a">0</span><span class="token punctuation" style="color:#24292e">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token comment" style="color:#6a737d;font-style:italic"># 插入适配器</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        hidden_states </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">adapter</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">hidden_states</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token keyword" style="color:#1890ff">return</span><span class="token plain"> hidden_states</span><br></span></code></pre></div></div>
<p><strong>(2)冻结原始模型参数</strong></p>
<p>在训练过程中，预训练模型的所有参数保持冻结，仅训练适配器模块的参数。这样可以避免对原始模型的破坏，同时大幅降低训练成本。</p>
<p>示例代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token comment" style="color:#6a737d;font-style:italic"># 冻结预训练模型参数，但保留适配器参数可训练</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> name</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> param </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> model</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">named_parameters</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">if</span><span class="token plain"> </span><span class="token string" style="color:#c41d7f">&quot;adapter&quot;</span><span class="token plain"> </span><span class="token keyword" style="color:#1890ff">not</span><span class="token plain"> </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> name</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 仅冻结非适配器参数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        param</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">requires_grad </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token boolean" style="color:#b5641a">False</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 仅训练适配器模块参数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 优化器仅包含适配器参数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">optimizer </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">optim</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Adam</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token punctuation" style="color:#24292e">[</span><span class="token plain">param </span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> name</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> param </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> model</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">named_parameters</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token keyword" style="color:#1890ff">if</span><span class="token plain"> </span><span class="token string" style="color:#c41d7f">&quot;adapter&quot;</span><span class="token plain"> </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> name</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    lr</span><span class="token operator" style="color:#24292e">=</span><span class="token number" style="color:#b5641a">1e-4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token punctuation" style="color:#24292e">)</span><br></span></code></pre></div></div>
<p><strong>(3)训练适配器模块</strong></p>
<p>通过反向传播更新适配器模块的参数，使其逐渐适应目标任务。训练流程与传统微调类似，但计算开销显著降低。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token comment" style="color:#6a737d;font-style:italic"># 训练循环</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> batch </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> dataloader</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    optimizer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">zero_grad</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    inputs </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">batch</span><span class="token punctuation" style="color:#24292e">[</span><span class="token string" style="color:#c41d7f">&#x27;text&#x27;</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> return_tensors</span><span class="token operator" style="color:#24292e">=</span><span class="token string" style="color:#c41d7f">&#x27;pt&#x27;</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">                       padding</span><span class="token operator" style="color:#24292e">=</span><span class="token boolean" style="color:#b5641a">True</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    outputs </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#24292e">(</span><span class="token operator" style="color:#24292e">**</span><span class="token plain">inputs</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">logits </span><span class="token comment" style="color:#6a737d;font-style:italic"># 假设任务为分类，logits为输出</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    loss </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> loss_function</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">outputs</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> batch</span><span class="token punctuation" style="color:#24292e">[</span><span class="token string" style="color:#c41d7f">&#x27;labels&#x27;</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 确保标签形状匹配</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    loss</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    optimizer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">step</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="36-低秩适配-low-rank-adaptation-lora">3.6 低秩适配 (Low-Rank Adaptation, LoRA)<a href="#36-低秩适配-low-rank-adaptation-lora" class="hash-link" aria-label="Direct link to 3.6 低秩适配 (Low-Rank Adaptation, LoRA)" title="Direct link to 3.6 低秩适配 (Low-Rank Adaptation, LoRA)" translate="no">​</a></h3>
<p>低秩适配（LoRA）是一种基于低秩分解的参数高效微调（PEFT）方法。其核心思想是将需要调整的权重矩阵分解为两个低秩矩阵，并仅训练这些低秩矩阵，而原始模型的权重保持冻结。这种方法通过低秩近似显著减少了需要训练的参数数量，同时保持了较高的任务性能。</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="1核心">1.核心<a href="#1核心" class="hash-link" aria-label="Direct link to 1.核心" title="Direct link to 1.核心" translate="no">​</a></h4>
<p>在深度学习模型中，许多权重矩阵（如全连接层或注意力机制中的权重）通常具有高维度。直接微调这些矩阵会导致巨大的计算和存储开销。LoRA 的核心思想是利用线性代数中的<strong>低秩分解</strong>技术，将权重矩阵的变化量表示为两个低秩矩阵的乘积：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi><mo>=</mo><mi>A</mi><mo>⋅</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">\Delta W = A \cdot B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span></span>
<p>其中：</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span>: 权重矩阵的变化量。</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>: 形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>d</mi><mo separator="true">,</mo><mi>r</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[d, r]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal">d</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mclose">]</span></span></span></span> 的低秩矩阵。</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>: 形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>r</mi><mo separator="true">,</mo><mi>k</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[r, k]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mclose">]</span></span></span></span> 的低秩矩阵。</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span>: 低秩维度 (Rank)，通常远小于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">d</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>。</li>
</ul>
<p>通过这种方式，原本需要更新的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">d \times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span> 个参数被压缩为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo>×</mo><mi>r</mi><mo>+</mo><mi>r</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">d \times r + r \times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span> 个参数，从而大幅降低了训练成本。</p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="2实现步骤">2.实现步骤<a href="#2实现步骤" class="hash-link" aria-label="Direct link to 2.实现步骤" title="Direct link to 2.实现步骤" translate="no">​</a></h4>
<p><strong>(1)分解权重矩阵</strong></p>
<p>对于需要微调的权重矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span>，LoRA 将其变化量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\Delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span> 表示为两个低秩矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 的乘积：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>W</mi><mrow><mi>n</mi><mi>e</mi><mi>w</mi></mrow></msub><mo>=</mo><mi>W</mi><mo>+</mo><mi mathvariant="normal">Δ</mi><mi>W</mi><mo>=</mo><mi>W</mi><mo>+</mo><mi>A</mi><mo>⋅</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">W_{new} = W + \Delta W = W + A \cdot B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span></span>
<p>其中：</p>
<ul>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span>: 原始权重矩阵，保持冻结</li>
<li class=""><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>: 低秩矩阵，作为可训练参数。</li>
</ul>
<p>示例代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token keyword" style="color:#1890ff">class</span><span class="token plain"> </span><span class="token class-name" style="color:#0969da">LoRALayer</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Module</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">def</span><span class="token plain"> </span><span class="token function" style="color:#d46b08">__init__</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> original_layer</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> rank</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token builtin" style="color:#0969da">super</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">__init__</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">original_layer </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> original_layer </span><span class="token comment" style="color:#6a737d;font-style:italic"># 原始连接的层</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        input_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> original_layer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#24292e">[</span><span class="token number" style="color:#b5641a">1</span><span class="token punctuation" style="color:#24292e">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        output_dim </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> original_layer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">weight</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">shape</span><span class="token punctuation" style="color:#24292e">[</span><span class="token number" style="color:#b5641a">0</span><span class="token punctuation" style="color:#24292e">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">A </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Parameter</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">input_dim</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> rank</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 低秩矩阵A</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">B </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> nn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Parameter</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">randn</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">rank</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> output_dim</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token comment" style="color:#6a737d;font-style:italic"># 低秩矩阵B</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">def</span><span class="token plain"> </span><span class="token function" style="color:#d46b08">forward</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> x</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token comment" style="color:#6a737d;font-style:italic"># 原始权重的前向计算</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        original_output </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">original_layer</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token comment" style="color:#6a737d;font-style:italic"># 低秩调整部分</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        delta_w </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">matmul</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">A</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> self</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">B</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        </span><span class="token keyword" style="color:#1890ff">return</span><span class="token plain"> original_output </span><span class="token operator" style="color:#24292e">+</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">matmul</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> delta_w</span><span class="token punctuation" style="color:#24292e">)</span><br></span></code></pre></div></div>
<p><strong>(2)插入 LoRA 层到模型中</strong></p>
<p>遍历模型结构，将目标层替换为包含 LoRA 的层。</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token comment" style="color:#6a737d;font-style:italic"># 替换注意力层的全连接层为LoRA层</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> layer </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> model</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">encoder</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">layer</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    attn </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> layer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">attention</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">self</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token comment" style="color:#6a737d;font-style:italic"># 假设替换query层</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    original_query </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> attn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">query</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    lora_query </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> LoRALayer</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">original_query</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> rank</span><span class="token operator" style="color:#24292e">=</span><span class="token number" style="color:#b5641a">8</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    attn</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">query </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> lora_query</span><br></span></code></pre></div></div>
<p><strong>(3)冻结原始模型参数</strong></p>
<p>在训练过程中，预训练模型的所有参数保持冻结，仅训练低秩矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>。这样可以避免对原始模型的破坏，同时显著降低训练成本。</p>
<p>示例代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token comment" style="color:#6a737d;font-style:italic"># 冻结所有原始参数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> param </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> model</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">parameters</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    param</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">requires_grad </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token boolean" style="color:#b5641a">False</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 解冻LoRA参数（假设LoRA层已正确插入）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> param </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> model</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">parameters</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token keyword" style="color:#1890ff">if</span><span class="token plain"> </span><span class="token builtin" style="color:#0969da">hasattr</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">param</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token string" style="color:#c41d7f">&quot;A&quot;</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token keyword" style="color:#1890ff">or</span><span class="token plain"> </span><span class="token builtin" style="color:#0969da">hasattr</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">param</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> </span><span class="token string" style="color:#c41d7f">&quot;B&quot;</span><span class="token punctuation" style="color:#24292e">)</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">        param</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">requires_grad </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> </span><span class="token boolean" style="color:#b5641a">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token comment" style="color:#6a737d;font-style:italic"># 优化器仅包含LoRA参数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">optimizer </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">optim</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">Adam</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token punctuation" style="color:#24292e">[</span><span class="token plain">param </span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> name</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> param </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> model</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">named_parameters</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"> </span><span class="token keyword" style="color:#1890ff">if</span><span class="token plain"> </span><span class="token string" style="color:#c41d7f">&quot;A&quot;</span><span class="token plain"> </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> name </span><span class="token keyword" style="color:#1890ff">or</span><span class="token plain"> </span><span class="token string" style="color:#c41d7f">&quot;B&quot;</span><span class="token plain"> </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> name</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    lr</span><span class="token operator" style="color:#24292e">=</span><span class="token number" style="color:#b5641a">1e-4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token punctuation" style="color:#24292e">)</span><br></span></code></pre></div></div>
<p><strong>(4)训练低秩矩阵</strong></p>
<p>通过反向传播更新低秩矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>，使其逐渐适应目标任务。训练流程与传统微调类似，但计算开销显著降低。</p>
<p>示例代码：</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token comment" style="color:#6a737d;font-style:italic"># 训练循环</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token keyword" style="color:#1890ff">for</span><span class="token plain"> batch </span><span class="token keyword" style="color:#1890ff">in</span><span class="token plain"> dataloader</span><span class="token punctuation" style="color:#24292e">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    optimizer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">zero_grad</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    inputs </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> tokenizer</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">batch</span><span class="token punctuation" style="color:#24292e">[</span><span class="token string" style="color:#c41d7f">&#x27;text&#x27;</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> return_tensors</span><span class="token operator" style="color:#24292e">=</span><span class="token string" style="color:#c41d7f">&#x27;pt&#x27;</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">                       padding</span><span class="token operator" style="color:#24292e">=</span><span class="token boolean" style="color:#b5641a">True</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> truncation</span><span class="token operator" style="color:#24292e">=</span><span class="token boolean" style="color:#b5641a">True</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    outputs </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#24292e">(</span><span class="token operator" style="color:#24292e">**</span><span class="token plain">inputs</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    logits </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> outputs</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">logits</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token comment" style="color:#6a737d;font-style:italic"># 计算损失</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    loss </span><span class="token operator" style="color:#24292e">=</span><span class="token plain"> loss_function</span><span class="token punctuation" style="color:#24292e">(</span><span class="token plain">logits</span><span class="token punctuation" style="color:#24292e">,</span><span class="token plain"> batch</span><span class="token punctuation" style="color:#24292e">[</span><span class="token string" style="color:#c41d7f">&#x27;labels&#x27;</span><span class="token punctuation" style="color:#24292e">]</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token comment" style="color:#6a737d;font-style:italic"># 反向传播和优化</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    loss</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">backward</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    optimizer</span><span class="token punctuation" style="color:#24292e">.</span><span class="token plain">step</span><span class="token punctuation" style="color:#24292e">(</span><span class="token punctuation" style="color:#24292e">)</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="3特点与优势">3.特点与优势<a href="#3特点与优势" class="hash-link" aria-label="Direct link to 3.特点与优势" title="Direct link to 3.特点与优势" translate="no">​</a></h4>
<ul>
<li class=""><strong>低资源需求</strong>：通过低秩分解，LoRA 显著减少了需要训练的参数数量。例如，对于一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1024</mn><mo>×</mo><mn>1024</mn></mrow><annotation encoding="application/x-tex">1024 \times 1024</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1024</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1024</span></span></span></span> 的权重矩阵，如果选择 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">r=8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>，则需要训练的参数量从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1024</mn><mo>×</mo><mn>1024</mn><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mn>048</mn><mo separator="true">,</mo><mn>576</mn></mrow><annotation encoding="application/x-tex">1024 \times 1024 = 1,048,576</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1024</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1024</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">048</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">576</span></span></span></span> 减少到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1024</mn><mo>×</mo><mn>8</mn><mo>+</mo><mn>8</mn><mo>×</mo><mn>1024</mn><mo>=</mo><mn>16</mn><mo separator="true">,</mo><mn>384</mn></mrow><annotation encoding="application/x-tex">1024 \times 8 + 8 \times 1024 = 16,384</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1024</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1024</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8389em;vertical-align:-0.1944em"></span><span class="mord">16</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">384</span></span></span></span>。</li>
<li class=""><strong>高效性</strong>：由于训练参数量大幅减少，LoRA 在超大规模模型（如 GPT-3、PaLM）上表现出色，能够在极低资源消耗下实现高效微调。</li>
<li class=""><strong>任务性能</strong>：尽管参数量减少，LoRA 通过低秩近似仍能保持较高的任务性能，尤其适合生成式任务（如对话、翻译）。</li>
<li class=""><strong>灵活性</strong>：LoRA 可以应用于各种类型的权重矩阵（如全连接层、注意力机制中的权重等），适用范围广泛。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="4典型应用">4.典型应用<a href="#4典型应用" class="hash-link" aria-label="Direct link to 4.典型应用" title="Direct link to 4.典型应用" translate="no">​</a></h4>
<p>LoRA方法特别适合以下场景：</p>
<ul>
<li class=""><strong>超大规模模型微调</strong>：在资源受限的情况下，LoRA 能够高效微调超大规模语言模型（如 GPT-3、PaLM）。</li>
<li class=""><strong>多任务学习</strong>：不同任务可以使用独立的低秩矩阵，避免任务间的干扰。</li>
<li class=""><strong>领域适配</strong>：在特定领域（如医学、法律）中插入 LoRA 模块，提升模型在领域内的表现。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="5注意事项">5.注意事项<a href="#5注意事项" class="hash-link" aria-label="Direct link to 5.注意事项" title="Direct link to 5.注意事项" translate="no">​</a></h4>
<ul>
<li class=""><strong>低秩维度的选择</strong>：低秩维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span> 是一个超参数，通常需要根据任务复杂性和实验效果进行调整。较大的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span> 提升性能但增加参数数量，较小的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.02778em">r</span></span></span></span> 则降低性能。</li>
<li class=""><strong>权重初始化</strong>：低秩矩阵的初始化可能影响训练的收敛速度和最终性能，建议使用正交初始化或其他合适的初始化方法。</li>
<li class=""><strong>适用范围</strong>：LoRA 更适合权重矩阵较大的场景，对于小型模型可能效果有限。</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="对比与总结">对比与总结<a href="#对比与总结" class="hash-link" aria-label="Direct link to 对比与总结" title="Direct link to 对比与总结" translate="no">​</a></h2>
<table><thead><tr><th style="text-align:left">方法</th><th style="text-align:left">核心思想</th><th style="text-align:left">参数更新量</th><th style="text-align:left">适用场景</th><th style="text-align:left">优缺点</th></tr></thead><tbody><tr><td style="text-align:left">BitFit</td><td style="text-align:left">更新偏置参数</td><td style="text-align:left">极少</td><td style="text-align:left">资源受限场景</td><td style="text-align:left">简单但表达能力有限</td></tr><tr><td style="text-align:left">Prompt Tuning</td><td style="text-align:left">优化输入提示</td><td style="text-align:left">较少</td><td style="text-align:left">分类、生成任务</td><td style="text-align:left">表现稳定，但设计复杂</td></tr><tr><td style="text-align:left">Prefix Tuning</td><td style="text-align:left">添加可训练前缀向量</td><td style="text-align:left">中等</td><td style="text-align:left">生成式任务</td><td style="text-align:left">灵活但计算成本略高</td></tr><tr><td style="text-align:left">P-Tuning</td><td style="text-align:left">输入层加入软提示</td><td style="text-align:left">较少</td><td style="text-align:left">小数据集任务</td><td style="text-align:left">轻量化，适合资源有限场景</td></tr><tr><td style="text-align:left">Adapter</td><td style="text-align:left">插入适配器模块</td><td style="text-align:left">中等</td><td style="text-align:left">多任务学习</td><td style="text-align:left">模块化设计，扩展性强</td></tr><tr><td style="text-align:left">LoRA</td><td style="text-align:left">低秩分解参数矩阵</td><td style="text-align:left">极少</td><td style="text-align:left">超大规模模型微调</td><td style="text-align:left">高效且性能优异</td></tr></tbody></table></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/大模型应用/什么是参数高效微调/参数高效微调.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Blog/docs/大模型应用/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">大模型应用</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Blog/docs/大模型应用/大模型的微调与量化/大模型的微调与应用"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">大模型的微调</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-定义与背景" class="table-of-contents__link toc-highlight">1. 定义与背景</a><ul><li><a href="#背景" class="table-of-contents__link toc-highlight">背景</a></li></ul></li><li><a href="#2-为什么要参数高效微调" class="table-of-contents__link toc-highlight">2. 为什么要参数高效微调？</a><ul><li><a href="#21-传统微调的局限性" class="table-of-contents__link toc-highlight">2.1 传统微调的局限性</a></li><li><a href="#22-peft-的优势" class="table-of-contents__link toc-highlight">2.2 PEFT 的优势</a></li></ul></li><li><a href="#3-参数高效微调的常用方法" class="table-of-contents__link toc-highlight">3. 参数高效微调的常用方法</a><ul><li><a href="#31-bitfit" class="table-of-contents__link toc-highlight">3.1 BitFit</a></li><li><a href="#32-提示微调-prompt-tuning" class="table-of-contents__link toc-highlight">3.2 提示微调 (Prompt Tuning)</a></li><li><a href="#33-前缀微调-prefix-tuning" class="table-of-contents__link toc-highlight">3.3 前缀微调 (Prefix Tuning)</a></li><li><a href="#34-p-tuning" class="table-of-contents__link toc-highlight">3.4 P-Tuning</a></li></ul></li><li><a href="#总结" class="table-of-contents__link toc-highlight">总结</a><ul><li><a href="#35-适配器-adapter" class="table-of-contents__link toc-highlight">3.5 适配器 (Adapter)</a></li><li><a href="#36-低秩适配-low-rank-adaptation-lora" class="table-of-contents__link toc-highlight">3.6 低秩适配 (Low-Rank Adaptation, LoRA)</a></li></ul></li><li><a href="#对比与总结" class="table-of-contents__link toc-highlight">对比与总结</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © huangsitao 2025</div></div></div></footer></div>
</body>
</html>