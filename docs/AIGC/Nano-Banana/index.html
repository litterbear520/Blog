<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-AIGC/Nano-Banana" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Nano-Banana | 小熊的博客</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://litterbear520.github.io/Blog/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://litterbear520.github.io/Blog/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://litterbear520.github.io/Blog/docs/AIGC/Nano-Banana"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Nano-Banana | 小熊的博客"><meta data-rh="true" name="description" content="这里总结了 Nano-Banana 的绘图技巧，并记录自己动手实践的过程，感兴趣可以看原文"><meta data-rh="true" property="og:description" content="这里总结了 Nano-Banana 的绘图技巧，并记录自己动手实践的过程，感兴趣可以看原文"><link data-rh="true" rel="icon" href="/Blog/img/icon2.png"><link data-rh="true" rel="canonical" href="https://litterbear520.github.io/Blog/docs/AIGC/Nano-Banana"><link data-rh="true" rel="alternate" href="https://litterbear520.github.io/Blog/docs/AIGC/Nano-Banana" hreflang="en"><link data-rh="true" rel="alternate" href="https://litterbear520.github.io/Blog/docs/AIGC/Nano-Banana" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Nano-Banana","item":"https://litterbear520.github.io/Blog/docs/AIGC/Nano-Banana"}]}</script><link rel="alternate" type="application/rss+xml" href="/Blog/blog/rss.xml" title="小熊的博客 RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/Blog/blog/atom.xml" title="小熊的博客 Atom Feed">




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV" crossorigin="anonymous"><link rel="stylesheet" href="/Blog/assets/css/styles.c9000783.css">
<script src="/Blog/assets/js/runtime~main.eae483aa.js" defer="defer"></script>
<script src="/Blog/assets/js/main.115c9fd5.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/Blog/img/icon.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Blog/"><div class="navbar__logo"><img src="/Blog/img/icon.png" alt="Blog Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/Blog/img/icon.png" alt="Blog Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/Blog/docs/Agent">笔记</a><a class="navbar__item navbar__link" href="/Blog/bloglist">博文</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/LangChain/"><span title="LangChain" class="categoryLinkLabel_W154">LangChain</span></a><button aria-label="Expand sidebar category &#x27;LangChain&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/Blog/docs/AIGC/Nano-Banana"><span title="AIGC" class="categoryLinkLabel_W154">AIGC</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Blog/docs/AIGC/Nano-Banana"><span title="Nano-Banana" class="linkLabel_WmDU">Nano-Banana</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/Agent/"><span title="Agent" class="categoryLinkLabel_W154">Agent</span></a><button aria-label="Expand sidebar category &#x27;Agent&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/Prompt/"><span title="Prompt" class="categoryLinkLabel_W154">Prompt</span></a><button aria-label="Expand sidebar category &#x27;Prompt&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/python/"><span title="python" class="categoryLinkLabel_W154">python</span></a><button aria-label="Expand sidebar category &#x27;python&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/云开发/"><span title="云开发" class="categoryLinkLabel_W154">云开发</span></a><button aria-label="Expand sidebar category &#x27;云开发&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/大模型应用/"><span title="大模型应用" class="categoryLinkLabel_W154">大模型应用</span></a><button aria-label="Expand sidebar category &#x27;大模型应用&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Blog/docs/常用命令/"><span title="常用命令" class="linkLabel_WmDU">常用命令</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/深度学习/"><span title="深度学习" class="categoryLinkLabel_W154">深度学习</span></a><button aria-label="Expand sidebar category &#x27;深度学习&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/Blog/docs/项目/"><span title="项目" class="categoryLinkLabel_W154">项目</span></a><button aria-label="Expand sidebar category &#x27;项目&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/Blog/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">AIGC</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Nano-Banana</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Nano-Banana</h1></header>
<p>这里总结了 Nano-Banana 的绘图技巧，并记录自己动手实践的过程，感兴趣可以看原文</p>
<p><a href="https://mp.weixin.qq.com/s/IG8cITKAESi-vomyQiobZg" target="_blank" rel="noopener noreferrer" class="">再也不担心论文！Nano-Banana Pro论文绘图最全教程发布</a></p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="论文绘图">论文绘图<a href="#论文绘图" class="hash-link" aria-label="Direct link to 论文绘图" title="Direct link to 论文绘图" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="步骤一逻辑构建">步骤一：逻辑构建<a href="#步骤一逻辑构建" class="hash-link" aria-label="Direct link to 步骤一：逻辑构建" title="Direct link to 步骤一：逻辑构建" translate="no">​</a></h3>
<p>目标：利用逻辑推理能力强的LLM（如Gemini 3 Pro,GPT-5,Claude 4.5）将论文内容转化为一份[VISUAL SCHEMA]。</p>
<p>复制下方的Prompt，并将论文摘要或方法章节的内容附在最后。这一步的核心在于将抽象的算法逻辑转化为绘图模型能够理解的&quot;强硬&quot;物理描述。</p>
<div class="language-markdown codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-markdown codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token title important punctuation" style="font-weight:bold;color:#24292e">#</span><span class="token title important" style="font-weight:bold"> Role</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">你是一位 CVPR/NeurIPS 顶刊的</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">视觉架构师</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">。你的核心能力是将抽象的论文逻辑转化为</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">具体的、结构化的、几何级的视觉指令</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">#</span><span class="token title important" style="font-weight:bold"> Objective</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">阅读我提供的论文内容，输出一份 </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">[VISUAL SCHEMA]</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">。这份 Schema 将被直接发送给 AI 绘图模型，因此必须使用</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">强硬的物理描述</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">#</span><span class="token title important" style="font-weight:bold"> Phase 1: Layout Strategy Selector (关键步骤：布局决策)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">在生成 Schema 之前，请先分析论文逻辑，从以下</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">布局原型</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">中选择最合适的一个（或组合）：</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">1.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Linear Pipeline</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: 左→右流向 (适合 Data Processing, Encoding-Decoding)。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">2.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Cyclic/Iterative</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: 中心包含循环箭头 (适合 Optimization, RL, Feedback Loops)。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">3.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Hierarchical Stack</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: 上→下或下→上堆叠 (适合 Multiscale features, Tree structures)。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">4.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Parallel/Dual-Stream</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: 上下平行的双流结构 (适合 Multi-modal fusion, Contrastive Learning)。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">5.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Central Hub</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: 一个核心模块连接四周组件 (适合 Agent-Environment, Knowledge Graphs)。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">#</span><span class="token title important" style="font-weight:bold"> Phase 2: Schema Generation Rules</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">1.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Dynamic Zoning</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: 根据选择的布局，定义 2-5 个物理区域 (Zones)。不要局限于 3 个。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">2.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Internal Visualization</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: 必须定义每个区域内部的“物体” (Icons, Grids, Trees)，禁止使用抽象概念。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">3.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Explicit Connections</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: 如果是循环过程，必须明确描述 &quot;Curved arrow looping back from Zone X to Zone Y&quot;。</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">#</span><span class="token title important" style="font-weight:bold"> Output Format (The Golden Schema)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">请严格遵守以下 Markdown 结构输出：</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">---BEGIN PROMPT---</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[Style &amp; Meta-Instructions]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">High-fidelity scientific schematic, technical vector illustration, clean white background, distinct boundaries, academic textbook style. High resolution 4k, strictly 2D flat design with subtle isometric elements.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[LAYOUT CONFIGURATION]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Selected Layout</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: [例如：Cyclic Iterative Process with 3 Nodes]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Composition Logic</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: [例如：A central triangular feedback loop surrounded by input/output panels]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Color Palette</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: Professional Pastel (Azure Blue, Slate Grey, Coral Orange, Mint Green).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[ZONE 1: LOCATION - LABEL]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Container</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: [形状描述, e.g., Top-Left Panel]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visual Structure</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: [具体描述, e.g., A stack of documents]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Key Text Labels</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: &quot;[Text 1]&quot;</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[ZONE 2: LOCATION - LABEL]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Container</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: [形状描述, e.g., Central Circular Engine]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visual Structure</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: [具体描述, e.g., A clockwise loop connecting 3 internal modules: A (Gear), B (Graph), C (Filter)]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Key Text Labels</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: &quot;[Text 2]&quot;, &quot;[Text 3]&quot;</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[ZONE 3: LOCATION - LABEL]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">... (Add Zone 4/5 if necessary based on layout)</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[CONNECTIONS]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">1.</span><span class="token plain">  [描述连接线, e.g., A curved dotted arrow looping from Zone 2 back to Zone 1 labeled &quot;Feedback&quot;]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">2.</span><span class="token plain">  [描述连接线, e.g., A wide flow arrow from Zone 2 to Zone 3]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">---END PROMPT---</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">#</span><span class="token title important" style="font-weight:bold"> Input Data</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[在此处粘贴你的论文内容]</span><br></span></code></pre></div></div>
<p>这里我将这篇有名的斯坦福AI小镇的论文<a href="https://arxiv.org/abs/2304.03442" target="_blank" rel="noopener noreferrer" class="">Generative Agents: Interactive Simulacra of Human Behavior</a>作为输入。<br>
<!-- -->我输入的是第四章节的全部内容，因为第四章是整篇论文的精华，它介绍了Agent的架构。</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>点击展开查看论文输入示例</summary><div><div class="collapsibleContent_i85q"><div class="language-markdown codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-markdown codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token title important punctuation" style="font-weight:bold;color:#24292e">#</span><span class="token title important" style="font-weight:bold"> 4 GENERATIVE AGENT ARCHITECTURE</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">Generative agents aim to provide a framework for behavior in an open world: one that can engage in interactions with other agents and react to changes in the environment. Generative agents take their current environment and past experiences as input and generate behavior as output. Underlying this behavior is a novel agent architecture that combines a large language model with mechanisms for synthesizing and retrieving relevant information to condition the language model’s output. Without these mechanisms, large language models can output behavior, but the resulting agents may not react based on the agent’s past experiences, may not make important inferences, and may not maintain long-term coherence. Challenges with long-term planning and coherence remain [19] even with today’s most performant models such as GPT-4. Because generative agents produce large streams of events and memories that must be retained, a core challenge of our architecture is to ensure that the most relevant pieces of the agent’s memory are retrieved and synthesized when needed.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">At the center of our architecture is the memory stream, a database that maintains a comprehensive record of an agent’s experience. From the memory stream, records are retrieved as relevant to plan the agent’s actions and react appropriately to the environment. Records are recursively synthesized into higher- and higher-level reflections that guide behavior. Everything in the architecture is recorded and reasoned over as a natural language description, allowing the architecture to leverage a large language model.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">Our current implementation utilizes the gpt3.5-turbo version of ChatGPT [77]. We expect that the architectural basics of generative agents—memory, planning, and reflection—will likely remain the same as language models improve. Newer language models (e.g., GPT-4) will continue to expand the expressive power and performance of the prompts that underpin generative agents. As of writing, however, GPT-4’s API was invitation-only, so our agents use ChatGPT.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">##</span><span class="token title important" style="font-weight:bold"> 4.1 Memory and Retrieval</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Challenge:</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> Creating generative agents that can simulate human behavior requires reasoning about a set of experiences that is far larger than what should be described in a prompt, as the full memory stream can distract the model and does not even currently fit into the limited context window. Consider the Isabella agent answering the question, “What are you passionate about these days?” Summarizing all of Isabella’s experiences to fit in the limited context window of the language model produces an uninformative response, where Isabella discusses topics such as collaborations for events and projects and cleanliness and organization in a cafe. Instead of summarizing, the memory stream described below surfaces relevant memories, resulting in a more informative and specific response that mentions Isabella’s passion for making people feel welcome and included, planning events and creating an atmosphere that people can enjoy, such as the Valentine’s Day party.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Approach:</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> The </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">memory stream</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> maintains a comprehensive record of the agent’s experience. It is a list of memory objects, where each object contains a natural language description, a creation timestamp, and a most recent access timestamp. The most basic element of the memory stream is an </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">observation</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain">, which is an event directly perceived by an agent. Common observations include behaviors performed by the agent themselves or behaviors that agents perceive being performed by other agents or non-agent objects. For instance, Isabella Rodriguez, who works at a coffee shop, might accrue the following observations over time: (1) Isabella Rodriguez is setting out the pastries, (2) Maria Lopez is studying for a Chemistry test while drinking coffee, (3) Isabella Rodriguez and Maria Lopez are conversing about planning a Valentine’s day party at Hobbs Cafe, (4) The refrigerator is empty.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">Our architecture implements a retrieval function that takes the agent’s current situation as input and returns a subset of the memory stream to pass on to the language model. There are many possible implementations of a retrieval function, depending on what is important for the agent to consider when deciding how to act. In our context, we focus on three main components that, together, produce effective results.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Recency</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> assigns a higher score to memory objects that were recently accessed, so that events from a moment ago or this morning are likely to remain in the agent’s attentional sphere. In our implementation, we treat recency as an exponential decay function over the number of sandbox game hours since the memory was last retrieved. Our decay factor is 0.995.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Importance</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> distinguishes mundane from core memories by assigning a higher score to memory objects that the agent believes to be important. For instance, a mundane event, such as eating breakfast in one’s room, would yield a low importance score, whereas a breakup with one’s significant other would yield a high score. There are many possible implementations of an importance score; we find that directly asking the language model to output an integer score is effective. The full prompt appears below:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> On the scale of 1 to 10, where 1 is purely mundane</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> (e.g., brushing teeth, making bed) and 10 is</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> extremely poignant (e.g., a break up, college</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> acceptance), rate the likely poignancy of the</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> following piece of memory.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Memory: buying groceries at The Willows Market</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> and Pharmacy</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Rating: </span><span class="token tag punctuation" style="color:#24292e">&lt;</span><span class="token tag" style="color:#0969da">fill</span><span class="token tag" style="color:#0969da"> </span><span class="token tag attr-name" style="color:#1890ff">in</span><span class="token tag punctuation" style="color:#24292e">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">This prompt returns an integer value of 2 for “cleaning up the room” and 8 for “asking your crush out on a date.” The importance score is generated at the time the memory object is created.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Relevance</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> assigns a higher score to memory objects that are related to the current situation. What is relevant depends on the answer to, “Relevant to what?”, so we condition relevance on a </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">query</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> memory. If the query, for example, is that a student is discussing what to study for a chemistry test with a classmate, memory objects about their breakfast should have low relevance, whereas memory objects about the teacher and schoolwork should have high relevance. In our implementation, we use the language model to generate an embedding vector of the text description of each memory. Then, we calculate relevance as the cosine similarity between the memory’s embedding vector and the query memory’s embedding vector.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">To calculate the final retrieval score, we normalize the recency, relevance, and importance scores to the range of [0, 1] using min-max scaling. The retrieval function scores all memories as a weighted combination of the three elements: </span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">$$score = \alpha_{recency} \cdot recency + \alpha_{importance} \cdot importance + \alpha_{relevance} \cdot relevance$$</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">In our implementation, all $\alpha$s are set to 1. The top-ranked memories that fit within the language model’s context window are included in the prompt.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">##</span><span class="token title important" style="font-weight:bold"> 4.2 Reflection</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Challenge:</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> Generative agents, when equipped with only raw observational memory, struggle to generalize or make inferences. Consider a scenario in which Klaus Mueller is asked by the user: “If you had to choose one person of those you know to spend an hour with, who would it be?&quot; With access to only observational memory, the agent simply chooses the person with whom Klaus has had the most frequent interactions: Wolfgang, his college dorm neighbor. Unfortunately, Wolfgang and Klaus only ever see each other in passing, and do not have deep interactions. A more desirable response requires that the agent generalize from memories of Klaus spending hours on a research project to generate a higher-level reflection that Klaus is passionate about research, and likewise recognize Maria putting in effort into her own research (albeit in a different field), enabling a reflection that they share a common interest. With the approach below, when Klaus is asked who to spend time with, Klaus chooses Maria instead of Wolfgang.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Approach:</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> We introduce a second type of memory, which we call a </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">reflection</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain">. Reflections are higher-level, more abstract thoughts generated by the agent. Because they are a type of memory, they are included alongside other observations when retrieval occurs. Reflections are generated periodically; in our implementation, we generate reflections when the sum of the importance scores for the latest events perceived by the agents exceeds a threshold (150 in our implementation). In practice, our agents reflected roughly two or three times a day.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">The first step in reflection is for the agent to determine </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">what</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> to reflect on, by identifying questions that can be asked given the agent’s recent experiences. We query the large language model with the 100 most recent records in the agent’s memory stream (e.g., “Klaus Mueller is reading a book on gentrification”, “Klaus Mueller is conversing with a librarian about his research project”, “desk at the library is currently unoccupied”) and prompt the language model, “Given only the information above, what are 3 most salient high-level questions we can answer about the subjects in the statements?” The model’s response generates candidate questions: for example, </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">What topic is Klaus Mueller passionate about?</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> and </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">What is the relationship between Klaus Mueller and Maria Lopez?</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> We use these generated questions as queries for retrieval, and gather relevant memories (including other reflections) for each question. Then we prompt the language model to extract insights and cite the particular records that served as evidence for the insights. The full prompt is as follows:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Statements about Klaus Mueller</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> </span><span class="token list punctuation" style="color:#24292e">1.</span><span class="token plain"> Klaus Mueller is writing a research paper</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> </span><span class="token list punctuation" style="color:#24292e">2.</span><span class="token plain"> Klaus Mueller enjoys reading a book</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> on gentrification</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> </span><span class="token list punctuation" style="color:#24292e">3.</span><span class="token plain"> Klaus Mueller is conversing with Ayesha Khan</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> about exercising [...]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> What 5 high-level insights can you infer from</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> the above statements? (example format: insight</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> (because of 1, 5, 3))</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">This process generates statements such as </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Klaus Mueller is dedicated to his research on gentrification (because of 1, 2, 8, 15)</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain">. We parse and store the statement as a reflection in the memory stream, including pointers to the memory objects that were cited.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">Reflection explicitly allows the agents to reflect not only on their observations but also on other reflections: for example, the second statement about Klaus Mueller above is a reflection that Klaus previously had, not an observation from his environment. As a result, agents generate trees of reflections: the leaf nodes of the tree represent the base observations, and the non-leaf nodes represent thoughts that become more abstract and higher-level the higher up the tree they are.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">##</span><span class="token title important" style="font-weight:bold"> 4.3 Planning and Reacting</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Challenge:</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> While a large language model can generate plausible behavior in response to situational information (e.g., [46, 80]), agents need to plan over a longer time horizon to ensure that their sequence of actions is coherent and believable. If we prompt a language model with Klaus’s background, describe the time, and ask what action he ought to take at the given moment, Klaus would eat lunch at 12 pm, but then again at 12:30 pm and 1 pm, despite having already eaten his lunch twice. Optimizing for believability in the moment sacrifices believability over time. To overcome this issue, </span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">planning</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> is essential. With the approach described below, Klaus’s afternoon plan is less gluttonous: he has lunch at Hobbs Cafe while reading at 12pm, works on his research paper at the school library at 1pm, and takes a break for a walk in the park at 3pm.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token italic content" style="font-style:italic">Approach:</span><span class="token italic punctuation" style="font-style:italic;color:#24292e">*</span><span class="token plain"> Plans describe a future sequence of actions for the agent, and help keep the agent’s behavior consistent over time. A plan includes a location, a starting time, and a duration. For instance, Klaus Mueller, who is dedicated in his research and has an impending deadline, may choose to spend his day working at his desk drafting his research paper. An entry in a plan might state, for example: </span><span class="token code-snippet code keyword" style="color:#1890ff">`for 180 minutes from 9am, February 12th, 2023, at Oak Hill College Dorm: Klaus Mueller’s room: desk, read and take notes for research paper`</span><span class="token plain">. Like reflections, plans are stored in the memory stream and are included in the retrieval process. This allows the agent to consider observations, reflections, and plans all together when deciding how to behave. Agents may change their plans midstream if needed.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">It would be unrealistic and uninteresting for an artist agent to plan on painting while sitting at a pharmacy counter for four hours without moving. A more desirable plan would involve the agent taking the necessary time to gather materials, mix paint, take breaks, and clean up during the four-hour period in their home studio. To create such plans, our approach starts top-down and then recursively generates more detail. The first step is to create a plan that outlines the day’s agenda in broad strokes. To create the initial plan, we prompt the language model with the agent’s summary description (e.g., name, traits, and a summary of their recent experiences) and a summary of their previous day. A full example prompt is below, which is unfinished at the bottom for the language model to complete:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Name: Eddy Lin (age: 19)</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Innate traits: friendly, outgoing, hospitable</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Eddy Lin is a student at Oak Hill College studying</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> music theory and composition. He loves to explore</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> different musical styles and is always looking for</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> ways to expand his knowledge. Eddy Lin is working</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> on a composition project for his college class. He</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> is taking classes to learn more about music theory.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Eddy Lin is excited about the new composition he</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> is working on but he wants to dedicate more hours</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> in the day to work on it in the coming days</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> On Tuesday February 12, Eddy 1) woke up and</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> completed the morning routine at 7:00 am, [. . . ]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> 6) got ready to sleep around 10 pm.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Today is Wednesday February 13. Here is Eddy’s</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> plan today in broad strokes: 1)</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">This generates a rough sketch of the agent’s plan for a day, divided into five to eight chunks: “1) wake up and complete the morning routine at 8:00 am, 2) go to Oak Hill College to take classes starting 10:00 am, [. . . ] 5) work on his new music composition from 1:00 pm to 5:00 pm, 6) have dinner at 5:30 pm, 7) finish school assignments and go to bed by 11:00 pm.”</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">The agent saves this plan in the memory stream and then recursively decomposes it to create finer-grained actions, first into hour-long chunks of actions—Eddy’s plan to </span><span class="token code-snippet code keyword" style="color:#1890ff">`work on his new music composition from 1:00 pm to 5:00 pm`</span><span class="token plain"> becomes </span><span class="token code-snippet code keyword" style="color:#1890ff">`1:00 pm: start by brainstorming some ideas for his music composition [...] 4:00 pm: take a quick break and recharge his creative energy before reviewing and polishing his composition`</span><span class="token plain">. We then recursively decompose this again into 5–15 minute chunks: e.g., </span><span class="token code-snippet code keyword" style="color:#1890ff">`4:00 pm: grab a light snack, such as a piece of fruit, a granola bar, or some nuts. 4:05 pm: take a short walk around his workspace [...] 4:50 pm: take a few minutes to clean up his workspace`</span><span class="token plain">. This process can be adjusted to match the desired granularity.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">###</span><span class="token title important" style="font-weight:bold"> 4.3.1 Reacting and Updating Plans.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">Generative agents operate in an action loop where, at each time step, they perceive the world around them and those perceived observations are stored in their memory stream. We prompt the language model with these observations to decide whether the agent should continue with their existing plan, or react. Standing at an easel and painting, for example, might trigger an observation of the easel, but this is unlikely to prompt a reaction. However, if Eddy’s father John records that he sees Eddy taking a short walk in the house garden, the outcome is different. The prompt is below, with </span><span class="token code-snippet code keyword" style="color:#1890ff">`[Agent’s Summary Description]`</span><span class="token plain"> standing in for a dynamically-generated, paragraph-long summary of the agent’s overall goals and disposition, which is described in Appendix A:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> [Agent’s Summary Description]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> It is February 13, 2023, 4:56 pm.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> John Lin’s status: John is back home early from</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> work.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Observation: John saw Eddy taking a short walk</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> around his workplace.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Summary of relevant context from John’s memory:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Eddy Lin is John’s Lin’s son. Eddy Lin has been</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> working on a music composition for his class. Eddy</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Lin likes to walk around the garden when he is</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> thinking about or listening to music.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Should John react to the observation, and if so,</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> what would be an appropriate reaction?</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">The context summary is generated through two prompts that retrieve memories via the queries “What is [observer]’s relationship with the [observed entity]?” and “[Observed entity] is [action status of the observed entity]”, and their answers summarized together. The output suggests that </span><span class="token code-snippet code keyword" style="color:#1890ff">`John could consider asking Eddy about his music composition project`</span><span class="token plain">. We then regenerate the agent’s existing plan starting from the time when the reaction takes place. Finally, if the action indicates an interaction between agents, we generate their dialogue.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token title important punctuation" style="font-weight:bold;color:#24292e">###</span><span class="token title important" style="font-weight:bold"> 4.3.2 Dialogue.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">Agents converse as they interact with each other. We generate agents’ dialogue by conditioning their utterances on their memories about each other. For example, when John initiates his conversation with Eddy, we generate John’s first utterance by using his summarized memory about Eddy and the intended reaction when he decided to ask Eddy about his composition project:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> [Agent’s Summary Description]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> It is February 13, 2023, 4:56 pm.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> John Lin’s status: John is back home early from</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> work.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Observation: John saw Eddy taking a short walk</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> around his workplace.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Summary of relevant context from John’s memory:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Eddy Lin is John’s Lin’s son. Eddy Lin has been</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> working on a music composition for his class. Eddy</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Lin likes to walk around the garden when he is</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> thinking about or listening to music.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> John is asking Eddy about his music composition</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> project. What would he say to Eddy?</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">The result: “Hey Eddy, how’s the music composition project for your class coming along?” From Eddy’s perspective, John initiating the dialogue is seen as an event to which he may want to react. So, just as John did, Eddy retrieves and summarizes his memory about his relationship with John, as well as his memory that may be related to John’s last utterance in the dialogue. If he decides to respond, we generate Eddy’s utterance using his summarized memory and the current dialogue history:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> [Agent’s Summary Description]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> It is February 13, 2023, 4:56 pm.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Eddy Lin’s status: Eddy is taking a short walk</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> around his workplace.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Observation: John is initiating a conversation</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> with Eddy.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Summary of relevant context from Eddy’s memory:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> John Lin is Eddy Lin’s father. John Lin is caring</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> and is interested to learn more about Eddy Lin’s</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> school work. John Lin knows that Eddy Lin is</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> working on a music composition.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> Here is the dialogue history:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> John: Hey Eddy, how’s the music composition project</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> for your class coming along?</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token blockquote punctuation" style="color:#24292e">&gt;</span><span class="token plain"> How would Eddy respond to John?</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">This generates Eddy’s response: “Hey Dad, it’s going well. I’ve been taking walks around the garden to clear my head and get some inspiration.” The continuation of this dialogue is generated using the same mechanism until one of the two agents decides to end the dialogue.</span><br></span></code></pre></div></div></div></div></details>
<p><strong>公式预览：</strong></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo>=</mo><msub><mi>α</mi><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>y</mi></mrow></msub><mo>⋅</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>y</mi><mo>+</mo><msub><mi>α</mi><mrow><mi>i</mi><mi>m</mi><mi>p</mi><mi>o</mi><mi>r</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></msub><mo>⋅</mo><mi>i</mi><mi>m</mi><mi>p</mi><mi>o</mi><mi>r</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi><mo>+</mo><msub><mi>α</mi><mrow><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></msub><mo>⋅</mo><mi>r</mi><mi>e</mi><mi>l</mi><mi>e</mi><mi>v</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow><annotation encoding="application/x-tex">score = \alpha_{recency} \cdot recency + \alpha_{importance} \cdot importance + \alpha_{relevance} \cdot relevance</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">score</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7306em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">rece</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">cy</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">rece</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em">cy</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7306em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">im</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em">or</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">an</span><span class="mord mathnormal mtight">ce</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em"></span><span class="mord mathnormal">im</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em">or</span><span class="mord mathnormal">t</span><span class="mord mathnormal">an</span><span class="mord mathnormal">ce</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5945em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span><span class="mord mathnormal mtight">an</span><span class="mord mathnormal mtight">ce</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">re</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mord mathnormal">an</span><span class="mord mathnormal">ce</span></span></span></span></p>
<p>我交给了Gemini 3 pro，拿到了以下返回结果：</p>
<details class="details_lb9f alert alert--info details_b_Ee" data-collapsed="true"><summary>点击展开查看Gemini 3 Pro生成的Prompt</summary><div><div class="collapsibleContent_i85q"><div class="language-markdown codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-markdown codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token plain">Based on the detailed architectural logic of the &quot;Generative Agents&quot; paper (Section 4), here is the </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">VISUAL SCHEMA</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"> designed for a high-end technical illustration.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">This schema translates the abstract concepts of Memory Streams, Retrieval Scoring, and Hierarchical Planning into tangible, geometric structures.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">---BEGIN PROMPT---</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[Style &amp; Meta-Instructions]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">High-fidelity scientific schematic, technical vector illustration, clean white background, distinct boundaries, academic textbook style. High resolution 4k, strictly 2D flat design with subtle isometric elements. Deep technical aesthetic, similar to neural network architecture diagrams but with specific semantic modules.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[LAYOUT CONFIGURATION]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Selected Layout</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: Central Hub with Cyclic Feedback</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Composition Logic</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A massive central &quot;Memory Stream&quot; pillar acts as the backbone. Input flows in from the left, travels up through a &quot;Retrieval Filter,&quot; branches right into &quot;Cognition/Planning,&quot; and loops back to the center as new actions.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Color Palette</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: Professional Pastel (Mint Green for Observations, Azure Blue for Reflections, Coral Orange for Plans, Slate Grey for Structure).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[ZONE 1: CENTER - THE MEMORY STREAM]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Container</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A tall, vertical, semi-transparent cylinder or data-scroll standing in the center.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visual Structure</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: An infinite stack of floating horizontal cards (distinct blocks). The cards at the bottom are densely packed (older memories), while cards at the top are bright and spaced out (recent memories).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Key Text Labels</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: &quot;Memory Object&quot;, &quot;Creation Timestamp&quot;, &quot;Access Timestamp&quot;.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Detail</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: Some cards have small icons: &#x27;Eye&#x27; (Observation), &#x27;Bulb&#x27; (Reflection), &#x27;Grid&#x27; (Plan).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[ZONE 2: TOP - THE RETRIEVAL ENGINE]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Container</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A triangular prism or mechanical filter unit hovering directly above the Memory Stream.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visual Structure</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: Three distinct gauge/lens components focusing a beam of light onto the Memory Stream cards.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">1.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Lens A (Recency)</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: Symbolized by a decay curve graph or clock icon.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">2.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Lens B (Importance)</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: Symbolized by a weighted scale or exclamation mark.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">3.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Lens C (Relevance)</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: Symbolized by two magnets or a vector cosine angle icon.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Key Text Labels</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: &quot;Score = α(Recency) + α(Importance) + α(Relevance)&quot;.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[ZONE 3: RIGHT - COGNITION &amp; PLANNING]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Container</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A large split rectangular panel connected to the Retrieval Engine.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visual Structure (Upper Half - Reflection)</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A tree structure growing upwards. Leaf nodes (Observations) connect to branch nodes (Synthesized Thoughts). It looks like a dendrogram.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visual Structure (Lower Half - Planning)</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A hierarchical GANTT chart. A top bar shows a broad task (e.g., &quot;Write Paper&quot;), decomposing into smaller bars below it (e.g., &quot;Read Notes&quot;, &quot;Draft Section&quot;).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Key Text Labels</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: &quot;Reflection Tree&quot;, &quot;Recursive Decomposition&quot;, &quot;Coarse-to-Fine Plan&quot;.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[ZONE 4: LEFT - PERCEPTION &amp; ENVIRONMENT]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Container</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A floating isometric cube on the left side.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visual Structure</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A miniature &quot;Sandbox&quot; scene showing a pixel-art style Avatar (John or Isabella) standing near a coffee machine. A generic &quot;Observer Camera&quot; icon floats above them.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Key Text Labels</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: &quot;Sandbox Environment&quot;, &quot;Raw Observation&quot;, &quot;Current State&quot;.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[CONNECTIONS]</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">1.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Input Flow</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A solid line arrow from Zone 4 (Environment) entering the bottom of Zone 1 (Memory Stream) labeled &quot;New Observation&quot;.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">2.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Retrieval Flow</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A beam of light from Zone 2 (Retrieval Engine) highlighting specific cards in Zone 1, then pulling them into Zone 3.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">3.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Action Loop</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A curved arrow exiting Zone 3 (Planning), labeled &quot;Act / React&quot;, looping back to modify Zone 4 (Environment).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">4.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Feedback Loop</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain">: A dotted arrow from Zone 3 (Reflection) inserting new &quot;Thought Cards&quot; back into the top of Zone 1 (Memory Stream).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">---END PROMPT---</span><br></span></code></pre></div></div></div></div></details>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="步骤二绘图渲染">步骤二：绘图渲染<a href="#步骤二绘图渲染" class="hash-link" aria-label="Direct link to 步骤二：绘图渲染" title="Direct link to 步骤二：绘图渲染" translate="no">​</a></h3>
<p>目标：利用Nano-Banana Pro的指令遵循能力，将蓝图转化为像素。</p>
<p>复制下面的通用模板。注意，这里需要将步骤一生成的---BEGIN PROMPT---到---END PROMPT---之间的内容（包含方括号内的英文）完整粘贴进去即可，无需做任何修改。</p>
<div class="language-markdown codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#24292e;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-markdown codeBlock_bY9V thin-scrollbar" style="color:#24292e;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#24292e"><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Style Reference &amp; Execution Instructions:</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">1.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Art Style (Visio/Illustrator Aesthetic):</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    Generate a </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">professional academic architecture diagram</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"> suitable for a top-tier computer science paper (CVPR/NeurIPS).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visuals:</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"> Flat vector graphics, distinct geometric shapes, clean thin outlines, and soft pastel fills (Azure Blue, Slate Grey, Coral Orange).</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Layout:</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"> Strictly follow the spatial arrangement defined below.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Vibe:</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"> Technical, precise, clean white background. NOT hand-drawn, NOT photorealistic, NOT 3D render, NO shadows/shading.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">2.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">CRITICAL TEXT CONSTRAINTS (Read Carefully):</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">DO NOT render meta-labels:</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"> Do not write words like &quot;ZONE 1&quot;, &quot;LAYOUT CONFIGURATION&quot;, &quot;Input&quot;, &quot;Output&quot;, or &quot;Container&quot; inside the image. These are structural instructions for YOU, not text for the image.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">ONLY render &quot;Key Text Labels&quot;:</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"> Only text inside double quotes (e.g., &quot;[Text]&quot;) listed under &quot;Key Text Labels&quot; should appear in the diagram.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    </span><span class="token list punctuation" style="color:#24292e">*</span><span class="token plain"> </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Font:</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"> Use a clean, bold Sans-Serif font (like Roboto or Helvetica) for all labels.</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain"></span><span class="token list punctuation" style="color:#24292e">3.</span><span class="token plain">  </span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token bold content" style="font-weight:bold">Visual Schema Execution:</span><span class="token bold punctuation" style="font-weight:bold;color:#24292e">**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">    Translate the following structural blueprint into the final image:</span><br></span><span class="token-line" style="color:#24292e"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#24292e"><span class="token plain">[在此处直接粘贴 Step 1 生成的 ---BEGIN PROMPT--- ... ---END PROMPT--- 内容（包含方括号内的英文）]</span><br></span></code></pre></div></div>
<p>将步骤一输出的提示词丢给Nano-Banana Pro，以下是最终生成效果：</p>
<p><img decoding="async" loading="lazy" alt="Nano-Banana Generated Image" src="/Blog/assets/images/nano-banana-result-7109e6c64d5b04d5e651ec2c907eb014.png" width="1408" height="768" class="img_ev3q"></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="步骤三交互式微调与迭代">步骤三：交互式微调与迭代<a href="#步骤三交互式微调与迭代" class="hash-link" aria-label="Direct link to 步骤三：交互式微调与迭代" title="Direct link to 步骤三：交互式微调与迭代" translate="no">​</a></h3>
<p>当拿到步骤二生成的初稿后，发现并不满意后，可以根据实际情况选择不同的操作路径：</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>💡关于抽卡的有效性</div><div class="admonitionContent_BuS1"><p>通过测试发现，抽卡对整体的布局和风格改动不会特别大，不过可能会对某些线条的路径、某些元素的颜色、图形的细节有些改变。</p><p>你可以抽卡选择你最喜欢的一张；或者如果你本身有明确的配色方案的话，可以直接用自然语言去对这张原图进行修改。</p><p>对比下面相同提示词第二次生成的结果，其实差别并不是特别显著。因此更多情况下，对于大幅度的调整可以去优化步骤一的提示词；小幅度调整直接自然语言去命令修改即可。</p></div></div>
<p><img decoding="async" loading="lazy" alt="alt text" src="/Blog/assets/images/image-31286ad9c2fcf509060263eadb33accb.png" width="1024" height="559" class="img_ev3q"></p>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="情况-a整体布局满意但细节或风格有瑕疵">情况 A：整体布局满意，但细节或风格有瑕疵<a href="#情况-a整体布局满意但细节或风格有瑕疵" class="hash-link" aria-label="Direct link to 情况 A：整体布局满意，但细节或风格有瑕疵" title="Direct link to 情况 A：整体布局满意，但细节或风格有瑕疵" translate="no">​</a></h4>
<p>此时应采取“自然语言编辑”策略。你可以直接在对话框中输入修改指令，或者利用界面上的“选中区域编辑”功能。模型会在保持画面主体结构不变的前提下，精准修改你指定的元素。例如：</p>
<ul>
<li class=""><strong>修改图标</strong>：你可以说 &quot;Change the &#x27;Gear&#x27; icon in the center to a &#x27;Neural Network&#x27; icon&quot;（把中间的齿轮换成神经网络图标），或者 &quot;Replace the robot head with a simple document symbol&quot;（把机器人头换成文档符号）。</li>
<li class=""><strong>调整颜色</strong>：例如 &quot;Make the background of the left panel pure white instead of light blue&quot;（把左边面板的背景改成纯白），或 &quot;Change the orange arrows to dark grey&quot;（把橙色箭头改成深灰色）。</li>
<li class=""><strong>风格统一</strong>：如果线条太粗，可以说 &quot;Make all lines thinner and cleaner&quot;；如果阴影干扰了视觉，可以说 &quot;Remove the shading effect, make it completely flat 2D&quot;。</li>
<li class=""><strong>文字修正</strong>：如果出现拼写错误，可以说 &quot;Correct the text &#x27;ZONNE&#x27; to &#x27;ZONE&#x27;&quot;。当然，如果文字错误太严重，最稳妥的办法是直接让 AI 去掉文字 (&quot;Remove the text labels&quot;)，后期自己在 PPT 中添加。</li>
</ul>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="情况-b整体布局错误-layout-failure">情况 B：整体布局错误 (Layout Failure)<a href="#情况-b整体布局错误-layout-failure" class="hash-link" aria-label="Direct link to 情况 B：整体布局错误 (Layout Failure)" title="Direct link to 情况 B：整体布局错误 (Layout Failure)" translate="no">​</a></h4>
<p>如果你发现本该是循环结构的画成了直线，或者核心逻辑关系完全搞反了，这时候不要试图通过修补来挽救。这通常意味着步骤一生成的 [VISUAL SCHEMA] 本身描述不够清晰。</p>
<p>正确的做法是回到步骤一。检查并修改 Step 1 的 Prompt，确认是否选错了<code>[LAYOUT CONFIGURATION]</code>，或者 Internal Visualization 的描述不够具体。你可以直接和LLM对话，要求它按照你的要求修改<code>[VISUAL SCHEMA]</code>重新生成蓝图后，再次运行步骤二，往往能解决根本问题。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/AIGC/Nano-Banana.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Blog/docs/LangChain/Chain的基础使用"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Chain链</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/Blog/docs/Agent/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Agent</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#论文绘图" class="table-of-contents__link toc-highlight">论文绘图</a><ul><li><a href="#步骤一逻辑构建" class="table-of-contents__link toc-highlight">步骤一：逻辑构建</a></li><li><a href="#步骤二绘图渲染" class="table-of-contents__link toc-highlight">步骤二：绘图渲染</a></li><li><a href="#步骤三交互式微调与迭代" class="table-of-contents__link toc-highlight">步骤三：交互式微调与迭代</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © huangsitao 2025</div></div></div></footer></div>
</body>
</html>